# 가상 메모리 관리

## 요구 페이징

프로세스가 필요로 하는 데이터를 언제 메모리로 가져올지 결정하는 것은 가져오기(fetch) 정책이다. 프로세스가 요청할 때 가져오는 것이 일반적. 이를 요구 페이징(demand paging)

### 요구페이징 개요

프로세스를 실행할 때, 운영체제는 필요한 모듈만 메모리에 올려 실행하고 나머지는 필요하다고 판단될 때 메모리로 불러온다. 이는

- 메모리를 효율적으로 관리하기 위해서. 메모리가 꽉 찰수록 관리하기 어렵기 때문
- 응답 속도 향상을 위해. 용량이 큰 프로세스를 전부 메모리로 가져와 실행하면 응답이 늦어질 수 있다.

프로그램의 일부만 실행하고, 사용자가 **특정 기능을 요구할 때 해당 모듈을 메모리에 올리면(요구 페이징)**

- 메모리의 절약
- 메모리의 효율적 관리
- 프로세스의 응답 속도 향상

**미리 가져오기**는 요구페이징과 반대. 앞으로 쓰일 것이라 예상되는 페이지를 미리 가져오는 방식. 캐시.

### 페이지 테이블 엔트리(Page Table Entry, PTE)의 구조

가상 메모리의 크기 = 물리 메모리 + 스왑 영역(하드 디스크에 존재. but 메모리 관리자가 관리)

가상 메모리 시스템에서 사용자의 프로세스는 물리 메모리 또는 스왑 영역에 있다. 프로세스가 스왑영역에 있는 경우

- 요구 페이징으로 인해 첨부터 물리 메모리에 올라가지 못한 경우
- 메모리가 꽉 차서 스왑 영역으로 옮겨진 경우

둘 다 페이지 테이블에는 페이지가 메모리에 있는지, 스왑 영역에 있는지 표시해야 하는데, **유효 비트**를 사용한다.

PTE는 페이지 테이블의 한 행. 페이지 번호(테이블 인덱스), 플래그 비트, 프레임 번호로 구성

![pte](./images/09/pte.png) 

a = access bit	m = modified bit	v = valid bit	r = read	w = write	x = excute

- access bit : 페이지가 메모리에 올라온 후 사용한 적이 있으면 1, 아니면 0
- modified bit : 페이지가 메모리에 올라온 후 변경이 있었으면 1, 아니면 0
- valid bit : 페이지가 물리 메모리에 있으면 0, 아니면 1

프레임 번호는 가상 주소의 해당 페이지가 어느 프레임(물리 메모리)에 있는지 알려주는 자료 구조. **주소 필드**라고도 한다. 



### 페이지 부재

pte의 유효비트가 0이면 현재 물리메모리에 있어서, 주소필드에는 물리 메모리의 프레임 번호가 들어간다. 1이면 스왑 영역에 있기 때문에, 저장장치 내 주소가 들어간다.

프로세스가 페이지를 요청했을 때 페이지가 메모리에 없는 상화을 **페이지 부재(page fault)**라 한다. 페이지 부재시, 메모리 관리자는 **메모리의 빈 공간을 찾아** 새로운 페이지를 **스왑인** 한다. **유효비트는 0으로 바뀌고, 주소 필드의 값도 새로운 프레임**으로 바뀔 것. 만약 메모리 상에 빈 공간이 없으면? **페이지 교체 알고리즘**을 통해 페이지를 하나 골라 **스왑아웃** 시킨다.



### 지역성

페이지 교체 알고리즘이 **쫓아낼 페이지를 찾을 때**는 **지역성(locality)**을 바탕으로 한다.

기억장치에 접근하는 패턴이 메모리 전체에 고루 분포되는 것이 아닌 **특정 영역에 집중되는 성질**.

- 공간 지역성(spatial locality) : 현재 위치에서 가까운 데이터에 접근할 확률이 높다.
- 시간 지역성(temporal locality) : 현재를 기준으로 가까운 시간에 접근한 데이터에 접근할 확률이 높다.

이러한 지역성은 **캐시**에서 특히 많이 사용된다. 캐시를 통해 다음에 읽을 데이터를 미리 가져오는데, goto문 같은 걸 만나면 적중률이 떨어질 가능성이 높다. goto문 쓰지말자.



## 페이지 교체 알고리즘

메모리가 꽉 찼을 때 페이지를 스왑 영역으로 내보내는 **재배치 정책**

앞으로 사용하지 않을 페이지를 스왑 영역으로 보내는 것이 중요!

### FIFO 페이지 교체 알고리즘

메모리에 가장 먼저 들어온 페이지를 스왑아웃 한다.

큐를 통해 구현

장점

- 시간 지역성 성립.

단점

- 옛날에 올라왔더라도 자주 사용된 페이지가 스왑아웃 될 수 있다.

-> 2차 기회 페이지 교체 알고리즘으로 개선

### 최적 페이지 교체 알고리즘

미래의 메모리 접근 패턴을 보고, 가장 늦게 사용되어지는 페이지를 스왑아웃. but 현실적으로 불가능.

따라서 **최적 근접 알고리즘**인 **최근 최소 사용(Least Recently Used, LRU), 최소 빈도 사용(Least Frequently Used, LFU), 최근 미사용(Not Used Recently, NUR)** 알고리즘 사용.

- LRU : 가장 **예전에 사용된 페이지**를 스왑아웃. **FIFO는 가장 먼저 올라왔던 페이지를 제거**하지만, LRU는 메모리에 있는 페이지가 사용될 때
  - 접근 시간을 갱신, 스왑아웃 해야할 때 가장 예전에 사용된 페이지를 보낸다.
  - 또는 **참조 비트 시프트**를 이용한다. 페이지를 갱신할 때 **갱신하는 페이지의 MSB에 1을 추가하며 기존의 모든 페이지의 참조 비트를 오른쪽으로 시프트**한다.(새로 갱신된 페이지의 비트값이 가장 크다.) 스왑아웃 되는 페이지는 **참조 비트의 값이 가장 작은 페이지**가 된다. LFU와는 다름.
  - 결국 둘 다 가장 예전의 페이지를 찾기 위해 추가적인 메모리 공간을 사용해야 한다.
- LFU : 가장 빈도수가 적은 페이지를 스왑아웃
  - 페이지가 갱신될 때마다 빈도수를 증가시켜, 가장 빈도수가 떨어지는 페이지를 스왑아웃
- **NUR** : 최근 미사용 페이지 교체 알고리즘. LRU, LFU처럼 정확한 시간, 참조 비트, 횟수를 유지할 필요 없이, **페이지의 접근 경향을 2비트로 구분**해 스왑아웃 시킨다. **(참조, 변경)** 비트를 통해 결정. **(0, 0) -> (0, 1) -> (1, 0) -> (1, 1)** 순서대로 교체. 성능이 LRU, LFU와 같은데, 추가 bit가 2개만 필요해서 보통 사용한다.



### FIFO 변형 알고리즘

#### 2차 기회 페이지 교체 알고리즘

#### 시계 알고리즘



## 스레싱과 프레임 할당

**스레싱(threshing)** : 하드디스크의 입출력이 너무 많아져서 **잦은 페이지 부재로 작업이 멈춘 것 같은 상태.** 물리 메모리가 꽉 차서 새로운 프로그램을 메몰에 올리기 위해 **기존 프로그램을 스왑 영역으로 옮기는 횟수가 많아지기 때문.**

멀티 프로그램의 정도가 어느 정도를 넘어가면, CPU가 작업하는 시간보다 스왑아웃, 스왑인 하는 시간이 많아져 CPU 사용률이 폭락한다. 이 지점을 **스레싱 발생 지점**이라 한다. 물리메모리 크기를 늘려 스레싱 발생 지점을 뒤로 미루는 것으로 컴퓨터의 속도를 늘릴 수 있다. 완전 비례는 아님. 이미 어느정도 작업하기에 충분한 공간을 확보했다면, 더 늘려봤자니까.

그래서 각 프로세스에 프레임을 얼마나 할당하느냐에 따라 성능이 좌우된다. 나누어주는 정책은

- 정적 할당 : 프로세스의 크기 상관 없이 동등하게 프레임 할당.

- 동적 할당 : 그때그때 맞추어 프레임을 적당히 할당

  - 작업집합 모델

    지역성. 최근 일정 시간 동안 참조된 페이지들을 집합으로 만들고, 이 집합에 있는 페이지들을 물리 메모리에 유지하여 프로세스의 실행을 돕는다. 물리메모리에 유지할 페이지의 크기를 **작업집합 크기(작업집합에 들어갈 최대 페이지 수)**, 작업집합에 포함되는 페이지의 범위를 **작업집합 윈도우**.

  - 페이지 부재 빈도 : **페이지 부재 횟수를 기록하여 페이지 부재 비율을 계산**하는 방식. 페이지 부재 비율의 **상한선, 하한선**을 두어 상한선을 넘어가는 경우에는 프레임 할당. 하한선을 밑도는 경우에는 프레임 회수.

    



## 심화

### 쓰기 시점 복사

교재 p.457 ~ 459 참조

